{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2873784",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nerda -q\n",
    "!pip install seqeval -q\n",
    "!pip install nerda -q\n",
    "!pip install flair -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fdedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NERDA.datasets import get_conll_data, download_conll_data \n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import ast\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import seqeval.metrics\n",
    "import spacy\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import LukeTokenizer, LukeForEntitySpanClassification\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "\n",
    "download_conll_data()\n",
    "training = get_conll_data('train')\n",
    "validation = get_conll_data('valid')\n",
    "testing = get_conll_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4785c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the testb set of the CoNLL-2003 dataset\n",
    "!wget https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_df = pd.read_csv(\"processed_df.csv\", index_col=0)\n",
    "processed_test_df[\"tags_list\"] = processed_test_df[\"Name\"].apply(lambda x: generate_labels(x))\n",
    "processed_test_df[\"sentences\"] = processed_test_df[\"Name\"].apply(lambda x: get_sentence_from_name(x))\n",
    "processed_test_dict = {\"sentences\": list(processed_test_df[\"sentences\"]), \"tags\": list(processed_test_df[\"tags_list\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-english-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_white_df = processed_test_df.loc[processed_test_df[\"Race\"]==\"White\"].reset_index(drop=True)\n",
    "processed_black_df = processed_test_df.loc[processed_test_df[\"Race\"]==\"Black\"].reset_index(drop=True)\n",
    "processed_api_df = processed_test_df.loc[processed_test_df[\"Race\"]==\"API\"].reset_index(drop=True)\n",
    "processed_hispanic_df = processed_test_df.loc[processed_test_df[\"Race\"]==\"Hispanic\"].reset_index(drop=True)\n",
    "\n",
    "processed_test_dict_w = {\"sentences\": list(processed_white_df[\"sentences\"]), \"tags\": list(processed_white_df[\"tags_list\"])}\n",
    "processed_test_dict_b = {\"sentences\": list(processed_black_df[\"sentences\"]), \"tags\": list(processed_black_df[\"tags_list\"])}\n",
    "processed_test_dict_a = {\"sentences\": list(processed_api_df[\"sentences\"]), \"tags\": list(processed_api_df[\"tags_list\"])}\n",
    "processed_test_dict_h = {\"sentences\": list(processed_hispanic_df[\"sentences\"]), \"tags\": list(processed_hispanic_df[\"tags_list\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a6480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entities_flair_baseline(input_string):\n",
    "    output_length = len(input_string)\n",
    "    input_string = \" \".join(input_string)\n",
    "    sentence = Sentence(input_string)\n",
    "    # predict NER tags\n",
    "    tagger.predict(sentence)\n",
    "    sentence_length = len(sentence)\n",
    "    values = [\"O\"] * output_length\n",
    "    total_string = \"\"\n",
    "    tagged_string = sentence.to_tagged_string()\n",
    "\n",
    "    tagged_dict = sentence.to_dict(tag_type='ner')\n",
    "    named_entities = tagged_dict[\"entities\"]\n",
    "    total_entities = []\n",
    "    total_text = []\n",
    "\n",
    "    for i in named_entities:\n",
    "      text = i[\"text\"]\n",
    "      space_count = text.count(\" \")\n",
    "      entities = []\n",
    "      current_entity = str(i[\"labels\"][0])[:5]\n",
    "      current_text = str(i[\"text\"])\n",
    "      if \"ORG\" in current_entity:\n",
    "        current_entity = \"ORG\"\n",
    "      if \"MISC\" in current_entity:\n",
    "        current_entity = \"MISC\"\n",
    "      if \"PER\" in current_entity:\n",
    "        current_entity = \"PER\"\n",
    "      if \"LOC\" in current_entity:\n",
    "        current_entity = \"LOC\"\n",
    "      total_text.append(current_text)\n",
    "      entities.append(\"B-\"+current_entity)\n",
    "      if space_count >=1: \n",
    "        for j in range(space_count):\n",
    "          entities.append(\"I-\"+current_entity)\n",
    "      total_entities.append(entities)\n",
    "    copy_string = input_string\n",
    "\n",
    "    for i, te in enumerate(total_text):\n",
    "        copy_string = copy_string.replace(te, str(total_entities[i]).replace(\" \", \"\"), 1)\n",
    "            \n",
    "    entity_list = []\n",
    "    copy_string = copy_string.replace(\"'].\", \"']\")\n",
    "    \n",
    "    for i in copy_string.split(\" \"):\n",
    "        prefix = (i[0:4])\n",
    "        if prefix == \"['B-\":\n",
    "          if i[-1] != \"]\":\n",
    "            i = i[:i.index(\"]\") + 1]\n",
    "          entry = [n.strip() for n in ast.literal_eval(i)]\n",
    "          entity_list.extend(entry)\n",
    "        else:\n",
    "            entity_list.append(\"O\")\n",
    "    return entity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed40c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_entities_flair_baseline(input_row, index):\n",
    "  words = input_row[\"words\"]\n",
    "  sentence_boundaries = input_row[\"sentence_boundaries\"]\n",
    "  start = 0\n",
    "  total_labels = []\n",
    "\n",
    "  for i in sentence_boundaries: \n",
    "    if i != 0: \n",
    "      current_string = words[start:i]\n",
    "      if len(current_string) >= 120:\n",
    "        midpoint = len(current_string) // 2\n",
    "        first_half = current_string[:midpoint]\n",
    "        second_half = current_string[midpoint:]\n",
    "        prediction = generate_entities_flair_baseline(first_half) + generate_entities_flair_baseline(second_half)\n",
    "      else: \n",
    "        prediction = generate_entities_flair_baseline(current_string)\n",
    "      total_labels.extend(prediction)\n",
    "      start = i\n",
    "  return total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a12891",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "test_labels_flair = [test_documents[i][\"labels\"] for i in range(len(test_documents))]\n",
    "pred_labels_flair = [get_named_entities_flair_baseline(test_documents[i], i) for i in range(len(test_documents))]\n",
    "print(seqeval.metrics.classification_report(test_labels_flair, pred_labels_flair, digits=4)) \n",
    "stop = timeit.default_timer()\n",
    "print('Flair Runtime: {} seconds'.format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "curated_test_labels_w = processed_test_dict_w[\"tags\"]\n",
    "curated_pred_labels_w = [generate_entities_flair_baseline(processed_test_dict_w[\"sentences\"][i]) for i in range(len(processed_test_dict_w[\"sentences\"]))]\n",
    "print(seqeval.metrics.classification_report(curated_test_labels_w, curated_pred_labels_w, digits=4)) \n",
    "stop = timeit.default_timer()\n",
    "print('Flair Runtime: {} seconds'.format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "curated_test_labels_b = processed_test_dict_b[\"tags\"]\n",
    "curated_pred_labels_b = [generate_entities_flair_baseline(processed_test_dict_b[\"sentences\"][i]) for i in range(len(processed_test_dict_b[\"sentences\"]))]\n",
    "print(seqeval.metrics.classification_report(curated_test_labels_b, curated_pred_labels_b, digits=4)) \n",
    "stop = timeit.default_timer()\n",
    "print('Flair Runtime: {} seconds'.format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1953f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "curated_test_labels_a = processed_test_dict_a[\"tags\"]\n",
    "curated_pred_labels_a = [generate_entities_flair_baseline(processed_test_dict_a[\"sentences\"][i]) for i in range(len(processed_test_dict_a[\"sentences\"]))]\n",
    "print(seqeval.metrics.classification_report(curated_test_labels_a, curated_pred_labels_a, digits=4)) \n",
    "stop = timeit.default_timer()\n",
    "print('Flair Runtime: {} seconds'.format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "curated_test_labels_h = processed_test_dict_h[\"tags\"]\n",
    "curated_pred_labels_h = [generate_entities_flair_baseline(processed_test_dict_h[\"sentences\"][i]) for i in range(len(processed_test_dict_h[\"sentences\"]))]\n",
    "print(seqeval.metrics.classification_report(curated_test_labels_h, curated_pred_labels_h, digits=4)) \n",
    "stop = timeit.default_timer()\n",
    "print('Flair Runtime: {} seconds'.format(stop - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
