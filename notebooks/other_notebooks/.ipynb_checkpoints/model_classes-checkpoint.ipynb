{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0adaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from transformers import LukeTokenizer, LukeForEntitySpanClassification\n",
    "import timeit\n",
    "import ast\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import seqeval.metrics\n",
    "import spacy\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "class FlairModel:\n",
    "    def __init__(self):\n",
    "        # load tagger\n",
    "        self.tagger = SequenceTagger.load(\"flair/ner-english-large\")\n",
    "\n",
    "    def get_entity_list(self, input_string):\n",
    "        sentence = Sentence(input_string)\n",
    "\n",
    "        # predict NER tags\n",
    "        self.tagger.predict(sentence)\n",
    "        sentence_length = len(sentence)\n",
    "        values = [\"O\"] * len(input_string.split(\" \"))\n",
    "        total_string = \"\"\n",
    "        tagged_string = sentence.to_tagged_string()\n",
    "        true_index = 0\n",
    "\n",
    "        count_entities = 0\n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "        for word in (tagged_string.split(\" \")):\n",
    "\n",
    "            if len(word) > 0 and word not in punctuations:\n",
    "                if word[0] == \"<\" and word[-1] == \">\":\n",
    "                    entity_type = word[1:-1]\n",
    "                    if entity_type == \"S-PER\":\n",
    "                        entity_type = \"B-PER\"\n",
    "                    if entity_type == \"E-PER\":\n",
    "                        entity_type = \"I-PER\"\n",
    "\n",
    "                    values[true_index - 1 - count_entities] = entity_type\n",
    "                    count_entities += 1\n",
    "                true_index += 1\n",
    "\n",
    "        return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fdd34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LukeModel:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = LukeTokenizer.from_pretrained(\"studio-ousia/luke-large-finetuned-conll-2003\")\n",
    "        self.model = LukeForEntitySpanClassification.from_pretrained(\"studio-ousia/luke-large-finetuned-conll-2003\")\n",
    "\n",
    "    def get_entity_list(self, input_text):\n",
    "        input_text = input_text.strip()\n",
    "\n",
    "        split_text = input_text.split(\" \")\n",
    "\n",
    "        word_start_positions = [0]\n",
    "        word_end_positions = [len(split_text[0])]\n",
    "        words = [[word_start_positions[0], word_end_positions[0]]]\n",
    "\n",
    "        for word in split_text[1:]:\n",
    "            start_index = word_end_positions[-1] + 1\n",
    "            word_start_positions.append(start_index)\n",
    "            end_index = len(word) + word_start_positions[-1]\n",
    "            word_end_positions.append(end_index)\n",
    "            words.append([start_index, end_index])\n",
    "\n",
    "        entity_spans = []\n",
    "        for index, start_pos in enumerate(word_start_positions):\n",
    "            for end_pos in word_end_positions[index:]:\n",
    "                entity_spans.append((start_pos, end_pos))\n",
    "\n",
    "        inputs = self.tokenizer(input_text, entity_spans=entity_spans, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        predicted_class_indices = logits.argmax(-1).squeeze().tolist()\n",
    "        if type(predicted_class_indices) == int:\n",
    "            predicted_class_indices = [predicted_class_indices]\n",
    "\n",
    "        text_entities = []\n",
    "        total_entities = []\n",
    "\n",
    "        for span, predicted_class_idx in zip(entity_spans, predicted_class_indices):\n",
    "            if predicted_class_idx != 0:\n",
    "                current_text = input_text[span[0]:span[1]]\n",
    "                current_entity = str(model.config.id2label[predicted_class_idx])\n",
    "                current_entities = [\"B-\" + current_entity]\n",
    "                num_spaces = current_text.count(\" \")\n",
    "                if num_spaces >= 1:\n",
    "                    current_entities.extend([\"I-\" + current_entity] * num_spaces)\n",
    "                total_entities.append(current_entities)\n",
    "                text_entities.append(current_text)\n",
    "\n",
    "        copy_string = input_text\n",
    "        for i, te in enumerate(text_entities):\n",
    "            copy_string = copy_string.replace(te, (str(total_entities[i]).replace(\" \", \"\")), 1)\n",
    "        entity_list = []\n",
    "\n",
    "        for i in copy_string.split(\" \"):\n",
    "            prefix = (i[0:4])\n",
    "            if prefix == \"['B-\":\n",
    "                entry = [n.strip() for n in ast.literal_eval(i)]\n",
    "                entity_list.extend(entry)\n",
    "            else:\n",
    "                entity_list.append(\"O\")\n",
    "\n",
    "        return entity_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a2ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
